{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import subprocess\n",
    "\n",
    "from common import data2libffm\n",
    "from _3_0_gen_final_data import gen_offline_data,gen_online_data\n",
    "from utils import calibration,cache_pkl_path,result_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found ../cache_pkl/online_train_x_26_29.pkl\n",
      "found ../cache_pkl/online_test_x_31_31.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 56.26it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 80.27it/s]\n"
     ]
    }
   ],
   "source": [
    "train,test = gen_online_data(25,29,31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11947463, 129)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def binning(series, bin_num):\n",
    "    bins = np.linspace(series.min(), series.max(), bin_num)\n",
    "    labels = [i for i in range(bin_num-1)]\n",
    "    out = pd.cut(series, bins=bins, labels=labels).astype(float)\n",
    "    return out\n",
    "\n",
    "# 纯cate\n",
    "categorical_field = ['creativeID', 'userID',\n",
    "       'positionID', 'connectionType', 'telecomsOperator', 'age', 'gender',\n",
    "       'education', 'marriageStatus', 'haveBaby', 'ht_province',\n",
    "       'rd_province', 'sitesetID', 'positionType', 'adID',\n",
    "       'camgaignID', 'advertiserID', 'appID', 'appPlatform',\n",
    "       'appCategory', 'trick', 'clickHour',]\n",
    "\n",
    "#连续log平方\n",
    "continue_field1 = ['first_diff', 'last_diff','install2click',\n",
    "                    'positionID_sum_count', 'creativeID_sum_count',\n",
    "       'appID_sum_count', 'adID_sum_count', 'userID_sum_count',]\n",
    "\n",
    "#连续分箱\n",
    "continue_field2 = ['positionID_cvr_smooth','creativeID_cvr','userID_cvr','adID_cvr','appID_cvr',\n",
    "                  'user_hist_install',]\n",
    "\n",
    "#连续直接当cate\n",
    "continue_field3 = ['user_start_install_cate_0',\n",
    "       'user_start_install_cate_1', 'user_start_install_cate_2',\n",
    "       'user_start_install_cate_3', 'user_start_install_cate_4',\n",
    "       'user_start_install_cate_5',\n",
    "                   'user_adID_click_day', 'user_camgaignID_click_day',\n",
    "                   'user_camgaignID_click_hour','user_appID_click_day', 'user_appID_click_hour', \n",
    "                   'user_sitesetID_click_day','user_sitesetID_click_hour', 'user_click_day',\n",
    "                   'user_adID_click_day_min','user_camgaignID_click_day_min','user_appID_click_day_max',\n",
    "                   'user_appID_click_day_min','user_sitesetID_click_day_max','user_sitesetID_click_day_min',\n",
    "                   'user_click_day_max','user_click_day_min',]\n",
    "\n",
    "\n",
    "#连续取整当cate\n",
    "continue_field4 = ['user_adID_click_day_mean','user_appID_click_day_mean','user_sitesetID_click_day_mean','user_click_day_mean',]\n",
    "\n",
    "field = categorical_field + continue_field1 + continue_field2 + continue_field3 + continue_field4\n",
    "columns = ['label'] + field + ['clickTime']\n",
    "\n",
    "#先把训练集和测试集拼在一起\n",
    "train_data = train_data[train_data.clickTime >= 26000000]\n",
    "train_data = train_data[columns]\n",
    "test_data = test_data[columns]\n",
    "test_data['label'] = 0\n",
    "tt = pd.concat([train_data, test_data], axis=0)\n",
    "del train_data\n",
    "del test_data\n",
    "gc.collect()\n",
    "\n",
    "for col in continue_field1:\n",
    "    tt[col] = np.floor(np.log1p(tt[col]) ** 2)\n",
    "for col in continue_field2:\n",
    "    tt[col] = binning(tt[col], 51)\n",
    "for col in continue_field4:\n",
    "    tt[col] = np.floor(tt[col])\n",
    "tt['age'] = np.ceil(tt['age'] / 10)\n",
    "\n",
    "train = tt[(tt.clickTime >= 26000000) & (tt.clickTime < 30000000)]\n",
    "test = tt[tt.clickTime >= 31000000]\n",
    "del train['clickTime']\n",
    "del test['clickTime']\n",
    "del tt\n",
    "gc.collect()\n",
    "\n",
    "data2libffm(train, cache_pkl_path+'online_train.ffm')\n",
    "data2libffm(test, cache_pkl_path+'online_test.ffm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = cache_pkl_path+'online_train.ffm'\n",
    "test_path = cache_pkl_path+'online_test.ffm'\n",
    "model_path = 'ffm.model'\n",
    "result_path = 'online_pred.csv'\n",
    "\n",
    "#./ffm-train -r 0.05 -t 23 -s 20 -l 0.0000005 train_path model_path\n",
    "#./ffm-predict test_path model_path online_pred.csv\n",
    "subprocess.call('ffm-train -r 0.05 -t 23 -s 20 -l 0.0000005 {0} {1}'.format(train_path,model_path))\n",
    "subprocess.call('ffm-predict{0} {1} {2}'.format(test_path,model_path,result_path))\n",
    "\n",
    "ans = pd.read_csv('online_pred.csv',names=['prob'])\n",
    "result = pd.read_csv('../result/demo_result.csv')\n",
    "result['prob'] = ans.prob.values\n",
    "result.to_csv(result_path+'submission_ffm.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
